# ğŸ¦ Banking Data Engineering Pipeline (Bronze â†’ Silver â†’ Gold)

This project demonstrates an end-to-end data engineering pipeline for a simulated banking analytics use case. Built on **Databricks Community Edition** using **Apache Spark (PySpark)** and **Delta Lake**, it adheres to the Medallion Architecture: **Bronze**, **Silver**, and **Gold** layers.

---

## ğŸ“‚ Project Architecture

- ğŸ”¹ **Bronze Layer**:  
  Raw data ingestion of synthetic banking data (customers, transactions, branches, employee performance, and costs) using PySpark and stored in Delta format.

- ğŸ”¸ **Silver Layer**:  
  Cleansing and transformation of raw data â€” handling nulls, standardizing fields, applying filters, and joining datasets.

- ğŸ… **Gold Layer**:  
  Analytical outputs and business KPIs for decision-making dashboards.

---

## ğŸ“Š KPIs Implemented in Gold Layer

1. **Customer Retention Rate**  
   Identifies active customers and retention patterns over a rolling window.

2. **Daily Transaction Volume Growth**  
   Measures daily change trends using window functions.

3. **Average Transaction Value**  
   Calculates the mean transaction value across branches.

4. **Branch Performance (Employee KPI-based)**  
   Aggregates employee performance metrics across branches and rates branches.

5. **Branch Profitability**  
   Calculates net profit by subtracting branch-level cost from revenue.

6. **Customer Segments**  
   Groups customers based on activity and transaction behavior.

7. **Customer Feedback Score**  
   Derived from employee ratings, linked back to customer satisfaction indicators.

---

## âš ï¸ Data Quality Notes

> The synthetic dataset used in this project may contain **data discrepancies** like skewed distributions or missing values to simulate real-world inconsistencies.  
> Handling and correcting these is part of the transformation logic.

---

## ğŸ› ï¸ Technologies Used

- **Apache Spark (PySpark)** â€“ Distributed processing of large datasets  
- **Delta Lake** â€“ ACID-compliant storage layer for Bronze/Silver/Gold medallion architecture  
- **Databricks Community Edition** â€“ Development and interactive execution

---

## ğŸ”® Future Work

- â³ **Delta Loads (Incremental)** â€“ Simulate Change Data Capture with timestamp-based filtering  
- ğŸ§¬ **SCD Type 2 Implementation** â€“ Especially for customers or branches changing over time  
- ğŸ§ª **Data Validation Framework** â€“ Add Great Expectations or custom rule-based checks  
- ğŸ§± **Job Orchestration** â€“ Schedule notebooks with Airflow or Databricks Jobs  
- ğŸ” **Streaming Ingestion** â€“ Add Structured Streaming for near real-time data updates
